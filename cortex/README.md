# Cortex

Cortex is an autonomous AI agent CLI that intelligently executes tasks through natural language. It combines file operations, shell commands, code execution, and web search capabilities into a conversational terminal interface. Built on the Vercel AI SDK with a manual agent loop, Cortex reasons about your requests and autonomously chains together the right tools to get the job done—whether you need to refactor code, analyze data, automate workflows, or research technical solutions.

## Learning Objectives

This project demonstrates several advanced concepts for building production AI agents:

- **Manual Agent Loops** - Implementing a custom agent loop with `streamText` (Vercel AI SDK's function for streaming LLM responses token-by-token with tool support) instead of relying on framework auto-execution, giving you full control over the conversation flow and tool execution lifecycle
- **Tool Design Patterns** - Creating composable, well-defined tools with Zod schemas for validation, parallel execution strategies, and proper error handling
- **Spec-Driven Development (OpenSpec)** - Using OpenSpec for managing specifications, change proposals, and maintaining alignment between what's documented and what's built
- **Agent Evaluation (Laminar)** - Implementing systematic testing and evaluation of agent behaviors using real-world scenarios and structured test cases
- **Conversation Memory Management** - Handling multi-turn conversations with proper message history, context windows, and tool result formatting
- **Autonomous Task Execution** - Designing agents that can reason about complex requests and chain multiple tools together to accomplish goals without step-by-step human guidance

## Tech Stack

| Layer | Technology | Notes |
|-------|------------|-------|
| Runtime | Node.js | ES2022 modules |
| Language | TypeScript | Strict mode |
| LLM | Vercel AI SDK | `ai` + `@ai-sdk/openai` packages |
| Terminal UI | Ink | React-based terminal components |
| Linting/Formatting | Biome | Code style enforcement |
| Evaluation | Laminar | `@lmnr-ai/lmnr` for agent testing |
| Spec Management | OpenSpec | Spec-driven development workflow |

## Project Structure

```
src/
├── index.ts           # Development entry point (renders Ink app)
├── cli.ts             # CLI entry point with shebang (for global install)
├── types.ts           # Shared type definitions
├── agent/
│   ├── run.ts         # Agent runner with streamText loop
│   ├── executeTool.ts # Tool execution dispatcher
│   ├── system/        # System prompts
│   └── tools/         # Individual tool implementations
└── ui/
    ├── App.tsx        # Main Ink application
    ├── index.tsx      # UI exports
    └── components/    # Reusable UI components

dist/                  # Compiled JavaScript (generated by npm run build)
```

## Spec-Driven Development with OpenSpec

Cortex uses [OpenSpec](https://github.com/openspec-dev/openspec) for managing specifications and change proposals:

- `openspec/specs/` - Current specifications for what IS built
- `openspec/changes/` - Proposed changes for what SHOULD be built
- `openspec/project.md` - Project conventions and patterns

**Common Commands:**
```bash
openspec list              # View active change proposals
openspec list --specs      # View all specifications
openspec show [item]       # Display details of a change or spec
openspec validate --strict # Validate all specs and changes
```

When planning new features or architectural changes, create a change proposal in `openspec/changes/` before implementation. See `openspec/AGENTS.md` for detailed workflow guidance.

## Conventions

### Code Style
- ES modules only (`"type": "module"`)
- TypeScript strict mode
- Biome for linting and formatting
- Vercel AI SDK with manual agent loop (no auto-execution)

### File Naming
- camelCase for TypeScript files: `executeTool.ts`
- kebab-case for directories when needed

### TypeScript
- Target: ES2021
- Module: ES2022
- Strict type checking enabled

### Running the Agent

**Prerequisites:**

Before running Cortex, you need to configure API keys:

1. Copy `.env.example` to `.env`
2. Get your API keys:
   - **OpenAI API Key**: https://platform.openai.com/api-keys
   - **Laminar API Key**: https://www.lmnr.ai/ (for agent evaluation)
3. Add the keys to your `.env` file

**Global Installation (recommended):**
```bash
# Build and install globally
npm run build
npm install -g .

# Run from any directory
agi
```

**Development Mode:**
- `npm run dev` - Run with watch mode (auto-restart on changes)
- `npm run start` - Run directly via tsx
- Interactive Ink-based terminal UI

## Architecture

### Agent Loop Pattern
The core is a manual streamText loop with tool execution:

```
1. User sends message via Ink input
2. Append to conversation history (CoreMessage[])
3. Call streamText with history + tools
4. Stream tokens to UI via fullStream iteration
5. If finishReason === 'tool-calls':
   a. Execute tools in parallel (Promise.all)
   b. Append tool results to history
   c. Go to step 3
6. If finishReason !== 'tool-calls':
   a. Display final response
   b. Wait for next user input
```

### Conversation History
- Array of AI SDK CoreMessage objects
- Roles: `system`, `user`, `assistant`, `tool`
- Tool results use structured output: `{ type: 'text', value: string }`

### Tool Design
- Tools defined using AI SDK `tool()` helper with Zod schemas
- `inputSchema` defines parameters (validated by AI SDK)
- Optional `execute` function for tool implementation
- Tool dispatcher switches over tool name to call implementations

This project was done during a 2 day workshop on [FrontendMasters](https://frontendmasters.com) with [Scott Moss](https://github.com/Hendrixer).
